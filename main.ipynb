{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML4HPC: Ensemble of Forecasters\n",
    "\n",
    "### Team Members:\n",
    "- Luca Venerando Greco\n",
    "- Bice Marzagora\n",
    "- Elia Vaglietti\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries\n",
    "\n",
    "In this notebook, we start by importing several essential libraries that are used throughout the workflow:\n",
    "\n",
    "- `os`: Provides functions for interacting with the operating system, such as creating directories and handling file paths.\n",
    "- `sys`: Provides access to some variables used or maintained by the Python interpreter and to functions that interact strongly with the interpreter.\n",
    "- `matplotlib.pyplot`: A plotting library used for creating static, animated, and interactive visualizations in Python.\n",
    "- `numpy`: A fundamental package for scientific computing with Python, used for working with arrays and matrices.\n",
    "- `time`: Provides various time-related functions.\n",
    "- `tqdm`: A library for creating progress bars and progress meters.\n",
    "\n",
    "These libraries are crucial for tasks such as data manipulation, visualization, and managing the execution of jobs in a high-performance computing environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-02 17:14:28.763835: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-12-02 17:14:28.768357: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-12-02 17:14:28.780359: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1733156068.799426 1195325 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1733156068.805278 1195325 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-02 17:14:28.826551: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import mnist\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import grad\n",
    "import time\n",
    "import os\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Directory Setup and Job Configuration\n",
    "\n",
    "We now set up the necessary directories and define the job configurations. Specifically, we create folders for storing charts, data, and logs if they do not already exist. We also define the number of forecasters and nodes for different scaling tests.\n",
    "\n",
    "If no new data is needed, set the `GENERATE_DATA` variable to `False` to skip the data generation step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "\n",
    "charts_folder = \"charts\"\n",
    "data_folder = \"data\"\n",
    "logs_folder = \"logs\"\n",
    "\n",
    "if not os.path.exists(data_folder):\n",
    "    os.makedirs(data_folder)\n",
    "\n",
    "if not os.path.exists(logs_folder):\n",
    "    os.makedirs(logs_folder)\n",
    "\n",
    "if not os.path.exists(charts_folder):\n",
    "    os.makedirs(charts_folder)\n",
    "\n",
    "ten_nodes = 10\n",
    "strong_scaling_nodes = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]  # Number of nodes to test\n",
    "weak_scaling_nodes   = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]  # Number of nodes to test\n",
    "\n",
    "n_runs = 30\n",
    "\n",
    "GENERATE_DATA = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Job Submission Function\n",
    "\n",
    "We define a function `submit_job` that handles the submission of jobs to the scheduler. This function takes the number of nodes, the number of forecasters, and a job name as input parameters. It creates the necessary directories for storing data and logs, reads a template launch script, formats it with the provided parameters, writes the formatted script to a file, and submits the job using the `sbatch` command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit_job(launch_file, num_nodes, job_name, num_epochs):\n",
    "    num_tasks_per_node = 128\n",
    "\n",
    "    if num_tasks_per_node > 128:\n",
    "        print(\"The number of tasks per node should be less than or equal to 128\")\n",
    "        exit(1)\n",
    "\n",
    "    if not os.path.exists(f\"{data_folder}/{job_name}\"):\n",
    "        os.makedirs(f\"{data_folder}/{job_name}\")\n",
    "\n",
    "    if not os.path.exists(f\"{logs_folder}/{job_name}\"):\n",
    "        os.makedirs(f\"{logs_folder}/{job_name}\")\n",
    "\n",
    "    with open(launch_file, 'r') as file:\n",
    "        launch_script = file.read()\n",
    "\n",
    "    launch_script = launch_script.format(\n",
    "        num_nodes=num_nodes,\n",
    "        num_tasks_per_node=num_tasks_per_node,\n",
    "        current_dir=current_dir,\n",
    "        world_size=num_nodes*num_tasks_per_node,\n",
    "        num_epochs=num_epochs,\n",
    "        data_folder=f\"{data_folder}/{job_name}\",\n",
    "        logs_folder=f\"{logs_folder}/{job_name}\"\n",
    "    )\n",
    "\n",
    "    script_filename = f\"{logs_folder}/{job_name}/{launch_file.split('/')[-1]}\"\n",
    "    with open(script_filename, \"w\") as script_file:\n",
    "        script_file.write(launch_script)\n",
    "\n",
    "    os.system(f\"sbatch {script_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Test Functions\n",
    "\n",
    "In the following sections, we define functions to run different scalability tests. These functions will help us automate the process of submitting jobs for one million forecasters, strong scaling, and weak scaling tests. Each function will generate a unique job name, submit the job using the `submit_job` function, and return the job names for tracking purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ten_nodes_test():\n",
    "    job_names = []\n",
    "    for i in range(n_runs):\n",
    "        run_dir = f\"{data_folder}/ten_nodes_test/run_{i}\"\n",
    "        if not os.path.exists(run_dir):\n",
    "            os.makedirs(run_dir)\n",
    "        \n",
    "        job_name = f\"/ten_nodes_test/run_{i}\"\n",
    "\n",
    "        submit_job(ten_nodes, job_name)\n",
    "\n",
    "        job_names.append(job_name)\n",
    "\n",
    "    return job_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpu_test():\n",
    "    job_names = []\n",
    "    for i in range(n_runs):\n",
    "        run_dir = f\"{data_folder}/gpu_test/run_{i}\"\n",
    "        if not os.path.exists(run_dir):\n",
    "            os.makedirs(run_dir)\n",
    "        \n",
    "        job_name = f\"/gpu_test/run_{i}\"\n",
    "\n",
    "        submit_job(\"launchers/launch_gpu.sh\", 1, job_name, 10)\n",
    "\n",
    "        job_names.append(job_name)\n",
    "\n",
    "    return job_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strong_scaling():\n",
    "    job_names = []\n",
    "    for run in range(1):\n",
    "        for num_nodes in strong_scaling_nodes:\n",
    "            job_name = f\"/strong_scaling/run_{run}/nodes_{num_nodes}\"\n",
    "            submit_job(num_nodes, job_name)\n",
    "            job_names.append(job_name)\n",
    "    return job_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def weak_scaling():\n",
    "#     job_names = []\n",
    "#     for run in range(1):\n",
    "#         for num_nodes in weak_scaling_nodes:\n",
    "#             job_name = f\"/weak_scaling/run_{run}/nodes_{num_nodes}_forecasters_{weak_scaling_forecasters*num_nodes}\"\n",
    "#             submit_job(num_nodes, job_name)\n",
    "#             job_names.append(job_name)\n",
    "#     return job_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_test():\n",
    "    job_names = []\n",
    "    for i in range(n_runs):\n",
    "        run_dir = f\"{data_folder}/baseline_test/run_{i}\"\n",
    "        if not os.path.exists(run_dir):\n",
    "            os.makedirs(run_dir)\n",
    "        \n",
    "        job_name = f\"/baseline_test/run_{i}\"\n",
    "\n",
    "        submit_job(\"launchers/launch_baseline.sh\", 1, job_name, 10)\n",
    "\n",
    "        job_names.append(job_name)\n",
    "\n",
    "    return job_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Waiting for jobs\n",
    "\n",
    "Now we wait for all the jobs to complete, in the meantime the `tqdm` progress bar will be updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hostname: access1.aion-cluster.uni.lux\n"
     ]
    }
   ],
   "source": [
    "import socket\n",
    "\n",
    "hostname = socket.gethostname()\n",
    "print(f\"Hostname: {hostname}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 4584486\n",
      "Submitted batch job 4584487\n",
      "Submitted batch job 4584488\n",
      "Submitted batch job 4584489\n",
      "Submitted batch job 4584490\n",
      "Submitted batch job 4584491\n",
      "Submitted batch job 4584492\n",
      "Submitted batch job 4584493\n",
      "Submitted batch job 4584494\n",
      "Submitted batch job 4584495\n",
      "Submitted batch job 4584496\n",
      "Submitted batch job 4584497\n",
      "Submitted batch job 4584498\n",
      "Submitted batch job 4584499\n",
      "Submitted batch job 4584500\n",
      "Submitted batch job 4584501\n",
      "Submitted batch job 4584502\n",
      "Submitted batch job 4584503\n",
      "Submitted batch job 4584504\n",
      "Submitted batch job 4584505\n",
      "Submitted batch job 4584506\n",
      "Submitted batch job 4584507\n",
      "Submitted batch job 4584508\n",
      "Submitted batch job 4584509\n",
      "Submitted batch job 4584510\n",
      "Submitted batch job 4584511\n",
      "Submitted batch job 4584512\n",
      "Submitted batch job 4584514\n",
      "Submitted batch job 4584515\n",
      "Submitted batch job 4584516\n",
      "Waiting for jobs to finish...\n",
      "['/baseline_test/run_0', '/baseline_test/run_1', '/baseline_test/run_2', '/baseline_test/run_3', '/baseline_test/run_4', '/baseline_test/run_5', '/baseline_test/run_6', '/baseline_test/run_7', '/baseline_test/run_8', '/baseline_test/run_9', '/baseline_test/run_10', '/baseline_test/run_11', '/baseline_test/run_12', '/baseline_test/run_13', '/baseline_test/run_14', '/baseline_test/run_15', '/baseline_test/run_16', '/baseline_test/run_17', '/baseline_test/run_18', '/baseline_test/run_19', '/baseline_test/run_20', '/baseline_test/run_21', '/baseline_test/run_22', '/baseline_test/run_23', '/baseline_test/run_24', '/baseline_test/run_25', '/baseline_test/run_26', '/baseline_test/run_27', '/baseline_test/run_28', '/baseline_test/run_29']\n"
     ]
    }
   ],
   "source": [
    "all_jobs_to_wait = []\n",
    "\n",
    "if GENERATE_DATA:\n",
    "    # if hostname contains \"aion\":\n",
    "    if \"aion\" in hostname:\n",
    "        all_jobs_to_wait.extend(baseline_test())\n",
    "        # all_jobs_to_wait.extend(ten_nodes_test())\n",
    "        # all_jobs_to_wait.extend(strong_scaling())\n",
    "        # all_jobs_to_wait.extend(weak_scaling())\n",
    "    elif \"iris\" in hostname:\n",
    "        all_jobs_to_wait.extend(gpu_test())\n",
    "\n",
    "    print(\"Waiting for jobs to finish...\")\n",
    "    print(all_jobs_to_wait)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for job_name in tqdm(all_jobs_to_wait):\n",
    "    while not os.path.exists(f\"{data_folder}/{job_name}/timings.txt\"):\n",
    "        time.sleep(10)  # Poll every 10 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Timing Analysis\n",
    "\n",
    "In this section, we analyze the execution times for the one million forecasters test. We read the timing data from the generated files, calculate the mean and standard deviation of the execution times, and create a dataframe to summarize the results.\n",
    "\n",
    "The dataframe includes the following columns:\n",
    "- **Run**: The run identifier.\n",
    "- **Timing**: The total execution time for each run.\n",
    "- **Aggregate sum CPU time**: The sum of CPU times across all ranks for each run.\n",
    "- **Aggregate mean CPU time**: The mean CPU time across all ranks for each run.\n",
    "\n",
    "We then print the dataframe and the calculated mean and standard deviation of the execution times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_mean_and_std_of_times(job_name):\n",
    "    timings = []\n",
    "    cpu_times = []\n",
    "\n",
    "    for i in range(n_runs):\n",
    "        with open(f\"{data_folder}/{job_name}/run_{i}/timings.txt\", \"r\") as file:\n",
    "            lines = file.readlines()\n",
    "            timings.append(float(lines[0].lstrip(\"Real time:\")))\n",
    "            cpu_times.append(float(lines[1].lstrip(\"CPU time:\")))\n",
    "        \n",
    "    df = pd.DataFrame({\n",
    "        'Run': [f'run_{i}' for i in range(n_runs)],\n",
    "        'Timing': timings,\n",
    "        'CPU Time': cpu_times\n",
    "    })\n",
    "\n",
    "    mean_timing = df['Timing'].mean()\n",
    "    std_timing = df['Timing'].std()\n",
    "\n",
    "    return df, mean_timing, std_timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Test DataFrame:\n",
      "       Run      Timing    CPU Time\n",
      "0    run_0  28709.0652  39757.7324\n",
      "1    run_1  36566.1120  47746.8150\n",
      "2    run_2  31055.7411  41502.9126\n",
      "3    run_3  28726.7053  39774.6897\n",
      "4    run_4  36648.8478  47538.9791\n",
      "5    run_5  30798.2712  41696.3612\n",
      "6    run_6  28754.0781  39875.8302\n",
      "7    run_7  29904.9714  41372.7079\n",
      "8    run_8  36952.2636  48081.6617\n",
      "9    run_9  29912.6036  41221.4646\n",
      "10  run_10  30589.9110  41483.6396\n",
      "11  run_11  36125.5605  47388.1764\n",
      "12  run_12  28775.6875  39912.3642\n",
      "13  run_13  29876.3299  41287.4759\n",
      "14  run_14  28846.6141  39927.3059\n",
      "15  run_15  35719.2082  46932.3074\n",
      "16  run_16  29703.3193  41051.0415\n",
      "17  run_17  28895.6916  39990.9123\n",
      "18  run_18  36719.4498  47700.9287\n",
      "19  run_19  31030.9284  41815.6667\n",
      "20  run_20  29793.8221  41257.7382\n",
      "21  run_21  28752.4261  39817.0975\n",
      "22  run_22  31804.3652  42532.9634\n",
      "23  run_23  31249.3289  41405.2272\n",
      "24  run_24  29758.5783  41097.4697\n",
      "25  run_25  28831.0640  39913.4079\n",
      "26  run_26  29710.2823  41048.8701\n",
      "27  run_27  36139.7378  47623.7003\n",
      "28  run_28  31086.9730  41424.6732\n",
      "29  run_29  28391.1681  39323.7404\n",
      "Mean Timing: 31327.63684666667, Std Timing: 2992.6407510734048\n",
      "Baseline Test DataFrame:\n",
      "       Run      Timing     CPU Time\n",
      "0    run_0  21000.3335  125350.8652\n",
      "1    run_1  21235.3623  124940.0498\n",
      "2    run_2  20294.0090  120845.1633\n",
      "3    run_3  21409.5533  123700.7529\n",
      "4    run_4  20349.5300  122561.8157\n",
      "5    run_5  20465.7111  122373.6241\n",
      "6    run_6  20660.0385  123683.5923\n",
      "7    run_7  20294.3101  122461.5785\n",
      "8    run_8  21259.3889  124099.1364\n",
      "9    run_9  19980.8211  120461.6832\n",
      "10  run_10  21293.3333  124818.3953\n",
      "11  run_11  22036.4213  131289.0063\n",
      "12  run_12  20946.0840  124006.4070\n",
      "13  run_13  21104.3832  122540.7872\n",
      "14  run_14  20815.4893  123320.2707\n",
      "15  run_15  20448.9391  122097.3327\n",
      "16  run_16  20403.3794  121039.6992\n",
      "17  run_17  20064.5158  120558.2553\n",
      "18  run_18  20107.6543  121589.2844\n",
      "19  run_19  21056.8659  122701.7726\n",
      "20  run_20  21834.8513  127576.8120\n",
      "21  run_21  21048.0130  123386.6141\n",
      "22  run_22  20574.5487  125176.1155\n",
      "23  run_23  20671.6475  121457.9938\n",
      "24  run_24  21187.5722  125896.7599\n",
      "25  run_25  20159.8992  116775.7150\n",
      "26  run_26  21099.7381  128473.2543\n",
      "27  run_27  20079.4468  122817.9647\n",
      "28  run_28  20951.7403  122316.8121\n",
      "29  run_29  21515.0352  126074.8136\n",
      "Mean Timing: 20811.62052333333, Std Timing: 540.7991858817841\n",
      "Speedup: 0.6643214304735447\n"
     ]
    }
   ],
   "source": [
    "# Get the dataframe for GPU test\n",
    "df_gpu, mean_timing_gpu, std_timing_gpu = get_mean_and_std_of_times(\"gpu_test\")\n",
    "print(\"GPU Test DataFrame:\")\n",
    "print(df_gpu)\n",
    "print(f\"Mean Timing: {mean_timing_gpu}, Std Timing: {std_timing_gpu}\")\n",
    "\n",
    "# Get the dataframe for Baseline test\n",
    "df_baseline, mean_timing_baseline, std_timing_baseline = get_mean_and_std_of_times(\"baseline_test\")\n",
    "print(\"Baseline Test DataFrame:\")\n",
    "print(df_baseline)\n",
    "print(f\"Mean Timing: {mean_timing_baseline}, Std Timing: {std_timing_baseline}\")\n",
    "\n",
    "# print mean speedup\n",
    "speedup = mean_timing_baseline / mean_timing_gpu\n",
    "print(f\"Speedup: {speedup}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU speedup analysis\n",
    "\n",
    "The results indicate that the GPU execution times are longer than the baseline CPU execution times. This can be attributed to the fact that the kernel size is too small to justify the overhead associated with using the GPU. \n",
    "\n",
    "GPUs are highly efficient for large-scale parallel computations, but they incur significant overhead for tasks such as data transfer between the CPU and GPU, kernel launch, and synchronization. When the computational workload is relatively small, these overheads can outweigh the benefits of parallel execution on the GPU, leading to longer overall execution times compared to the CPU. \n",
    "\n",
    "In this case, the small kernel size results in insufficient computational workload to fully utilize the GPU's capabilities, making the CPU a more efficient choice for this specific task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strong Scalability Test\n",
    "\n",
    "In this section, we analyze the execution times for the strong scalability test. We have already submitted jobs for different numbers of nodes and collected the execution times. The results are plotted on a logarithmic scale to better visualize the differences in execution times as the number of nodes increases.\n",
    "\n",
    "The strong scalability test helps us understand how the execution time decreases as we increase the number of nodes while keeping the problem size constant. Ideally, the execution time should decrease proportionally with the increase in the number of nodes, indicating efficient parallelization and resource utilization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution_times_strong_scaling = []\n",
    "\n",
    "# Submit jobs for each test configuration\n",
    "for num_nodes in strong_scaling_nodes:\n",
    "    execution_time_file = f\"{data_folder}/strong_scaling/run_0/nodes_{num_nodes}/timings.txt\"\n",
    "\n",
    "    with open(execution_time_file, \"r\") as f:\n",
    "        line = f.readline().strip()\n",
    "        execution_time = float(line.replace(\"Total execution time: \", \"\"))\n",
    "    execution_times_strong_scaling.append(execution_time)\n",
    "    print(f\"Execution time for {num_nodes} nodes: {execution_time} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.yscale('log')\n",
    "plt.plot(strong_scaling_nodes, execution_times_strong_scaling, label='Strong Scaling', marker='o')\n",
    "plt.xlabel('Number of Nodes')\n",
    "plt.ylabel('Execution Time (seconds)')\n",
    "plt.title('Strong Scalability Test')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.savefig(f\"{charts_folder}/scalability_plot.png\") \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weak Scalability Test\n",
    "\n",
    "In this section, we analyze the execution times for the weak scalability test. \n",
    "\n",
    "The weak scalability test helps us understand how the execution time changes as we increase the number of nodes while keeping the workload per node constant. Ideally, the execution time should remain constant with the increase in the number of nodes, indicating efficient parallelization and resource utilization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# execution_times_weak_scaling = []\n",
    "\n",
    "# # Submit jobs for each test configuration\n",
    "# for num_nodes in weak_scaling_nodes:\n",
    "#     execution_time_file = f\"{data_folder}/weak_scaling/run_0/nodes_{num_nodes}_forecasters_{weak_scaling_forecasters*num_nodes}/timings.txt\"\n",
    "\n",
    "#     with open(execution_time_file, \"r\") as f:\n",
    "#         line = f.readline().strip()\n",
    "#         execution_time = float(line.replace(\"Total execution time: \", \"\"))\n",
    "#     execution_times_weak_scaling.append(execution_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Plot the weak scalability results\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.plot(weak_scaling_nodes, execution_times_weak_scaling, label='Weak Scaling', marker='o')\n",
    "# plt.xlabel(\"Number of Nodes\")\n",
    "# plt.ylabel(\"Execution Time (seconds)\")\n",
    "# plt.title(\"Weak Scalability Test\")\n",
    "# plt.grid(True)\n",
    "# plt.savefig(f\"{charts_folder}/weak_scalability.png\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
