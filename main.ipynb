{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML4HPC: Ensemble of Forecasters\n",
    "\n",
    "### Team Members:\n",
    "- Luca Venerando Greco\n",
    "- Bice Marzagora\n",
    "- Elia Vaglietti\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries\n",
    "\n",
    "In this notebook, we start by importing several essential libraries that are used throughout the workflow:\n",
    "\n",
    "- `os`: Provides functions for interacting with the operating system, such as creating directories and handling file paths.\n",
    "- `sys`: Provides access to some variables used or maintained by the Python interpreter and to functions that interact strongly with the interpreter.\n",
    "- `matplotlib.pyplot`: A plotting library used for creating static, animated, and interactive visualizations in Python.\n",
    "- `numpy`: A fundamental package for scientific computing with Python, used for working with arrays and matrices.\n",
    "- `time`: Provides various time-related functions.\n",
    "- `tqdm`: A library for creating progress bars and progress meters.\n",
    "\n",
    "These libraries are crucial for tasks such as data manipulation, visualization, and managing the execution of jobs in a high-performance computing environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-02 15:06:49.134843: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-12-02 15:06:49.140195: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-12-02 15:06:49.152604: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1733148409.170811  624293 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1733148409.176549  624293 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-02 15:06:49.197588: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import mnist\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import grad\n",
    "import time\n",
    "import os\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Directory Setup and Job Configuration\n",
    "\n",
    "We now set up the necessary directories and define the job configurations. Specifically, we create folders for storing charts, data, and logs if they do not already exist. We also define the number of forecasters and nodes for different scaling tests.\n",
    "\n",
    "If no new data is needed, set the `GENERATE_DATA` variable to `False` to skip the data generation step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "\n",
    "charts_folder = \"charts\"\n",
    "data_folder = \"data\"\n",
    "logs_folder = \"logs\"\n",
    "\n",
    "if not os.path.exists(data_folder):\n",
    "    os.makedirs(data_folder)\n",
    "\n",
    "if not os.path.exists(logs_folder):\n",
    "    os.makedirs(logs_folder)\n",
    "\n",
    "if not os.path.exists(charts_folder):\n",
    "    os.makedirs(charts_folder)\n",
    "\n",
    "ten_nodes = 10\n",
    "strong_scaling_nodes = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]  # Number of nodes to test\n",
    "weak_scaling_nodes   = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]  # Number of nodes to test\n",
    "\n",
    "n_runs = 30\n",
    "\n",
    "GENERATE_DATA = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Job Submission Function\n",
    "\n",
    "We define a function `submit_job` that handles the submission of jobs to the scheduler. This function takes the number of nodes, the number of forecasters, and a job name as input parameters. It creates the necessary directories for storing data and logs, reads a template launch script, formats it with the provided parameters, writes the formatted script to a file, and submits the job using the `sbatch` command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit_job(launch_file, num_nodes, job_name, num_epochs):\n",
    "    num_tasks_per_node = 128\n",
    "\n",
    "    if num_tasks_per_node > 128:\n",
    "        print(\"The number of tasks per node should be less than or equal to 128\")\n",
    "        exit(1)\n",
    "\n",
    "    if not os.path.exists(f\"{data_folder}/{job_name}\"):\n",
    "        os.makedirs(f\"{data_folder}/{job_name}\")\n",
    "\n",
    "    if not os.path.exists(f\"{logs_folder}/{job_name}\"):\n",
    "        os.makedirs(f\"{logs_folder}/{job_name}\")\n",
    "\n",
    "    with open(launch_file, 'r') as file:\n",
    "        launch_script = file.read()\n",
    "\n",
    "    launch_script = launch_script.format(\n",
    "        num_nodes=num_nodes,\n",
    "        num_tasks_per_node=num_tasks_per_node,\n",
    "        current_dir=current_dir,\n",
    "        world_size=num_nodes*num_tasks_per_node,\n",
    "        num_epochs=num_epochs,\n",
    "        data_folder=f\"{data_folder}/{job_name}\",\n",
    "        logs_folder=f\"{logs_folder}/{job_name}\"\n",
    "    )\n",
    "\n",
    "    script_filename = f\"{logs_folder}/{job_name}/{launch_file.split('/')[-1]}\"\n",
    "    with open(script_filename, \"w\") as script_file:\n",
    "        script_file.write(launch_script)\n",
    "\n",
    "    os.system(f\"sbatch {script_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Test Functions\n",
    "\n",
    "In the following sections, we define functions to run different scalability tests. These functions will help us automate the process of submitting jobs for one million forecasters, strong scaling, and weak scaling tests. Each function will generate a unique job name, submit the job using the `submit_job` function, and return the job names for tracking purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ten_nodes_test():\n",
    "    job_names = []\n",
    "    for i in range(n_runs):\n",
    "        run_dir = f\"{data_folder}/ten_nodes_test/run_{i}\"\n",
    "        if not os.path.exists(run_dir):\n",
    "            os.makedirs(run_dir)\n",
    "        \n",
    "        job_name = f\"/ten_nodes_test/run_{i}\"\n",
    "\n",
    "        submit_job(ten_nodes, job_name)\n",
    "\n",
    "        job_names.append(job_name)\n",
    "\n",
    "    return job_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strong_scaling():\n",
    "    job_names = []\n",
    "    for run in range(1):\n",
    "        for num_nodes in strong_scaling_nodes:\n",
    "            job_name = f\"/strong_scaling/run_{run}/nodes_{num_nodes}\"\n",
    "            submit_job(num_nodes, job_name)\n",
    "            job_names.append(job_name)\n",
    "    return job_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def weak_scaling():\n",
    "#     job_names = []\n",
    "#     for run in range(1):\n",
    "#         for num_nodes in weak_scaling_nodes:\n",
    "#             job_name = f\"/weak_scaling/run_{run}/nodes_{num_nodes}_forecasters_{weak_scaling_forecasters*num_nodes}\"\n",
    "#             submit_job(num_nodes, job_name)\n",
    "#             job_names.append(job_name)\n",
    "#     return job_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_test():\n",
    "    job_names = []\n",
    "    for i in range(n_runs):\n",
    "        run_dir = f\"{data_folder}/baseline_test/run_{i}\"\n",
    "        if not os.path.exists(run_dir):\n",
    "            os.makedirs(run_dir)\n",
    "        \n",
    "        job_name = f\"/baseline_test/run_{i}\"\n",
    "\n",
    "        submit_job(\"launch_baseline.sh\", 1, job_name, 10)\n",
    "\n",
    "        job_names.append(job_name)\n",
    "\n",
    "    return job_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Waiting for jobs\n",
    "\n",
    "Now we wait for all the jobs to complete, in the meantime the `tqdm` progress bar will be updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 4580471\n",
      "Submitted batch job 4580472\n",
      "Submitted batch job 4580473\n",
      "Submitted batch job 4580474\n",
      "Submitted batch job 4580475\n",
      "Submitted batch job 4580476\n",
      "Submitted batch job 4580477\n",
      "Submitted batch job 4580478\n",
      "Submitted batch job 4580479\n",
      "Submitted batch job 4580480\n",
      "Submitted batch job 4580481\n",
      "Submitted batch job 4580482\n",
      "Submitted batch job 4580483\n",
      "Submitted batch job 4580484\n",
      "Submitted batch job 4580485\n",
      "Submitted batch job 4580486\n",
      "Submitted batch job 4580487\n",
      "Submitted batch job 4580488\n",
      "Submitted batch job 4580489\n",
      "Submitted batch job 4580490\n",
      "Submitted batch job 4580491\n",
      "Submitted batch job 4580492\n",
      "Submitted batch job 4580493\n",
      "Submitted batch job 4580494\n",
      "Submitted batch job 4580495\n",
      "Submitted batch job 4580496\n",
      "Submitted batch job 4580497\n",
      "Submitted batch job 4580498\n",
      "Submitted batch job 4580499\n",
      "Submitted batch job 4580500\n",
      "Waiting for jobs to finish...\n",
      "['/baseline_test/run_0', '/baseline_test/run_1', '/baseline_test/run_2', '/baseline_test/run_3', '/baseline_test/run_4', '/baseline_test/run_5', '/baseline_test/run_6', '/baseline_test/run_7', '/baseline_test/run_8', '/baseline_test/run_9', '/baseline_test/run_10', '/baseline_test/run_11', '/baseline_test/run_12', '/baseline_test/run_13', '/baseline_test/run_14', '/baseline_test/run_15', '/baseline_test/run_16', '/baseline_test/run_17', '/baseline_test/run_18', '/baseline_test/run_19', '/baseline_test/run_20', '/baseline_test/run_21', '/baseline_test/run_22', '/baseline_test/run_23', '/baseline_test/run_24', '/baseline_test/run_25', '/baseline_test/run_26', '/baseline_test/run_27', '/baseline_test/run_28', '/baseline_test/run_29']\n"
     ]
    }
   ],
   "source": [
    "all_jobs_to_wait = []\n",
    "\n",
    "if GENERATE_DATA:\n",
    "    # all_jobs_to_wait.extend(baseline_test())\n",
    "    # all_jobs_to_wait.extend(ten_nodes_test())\n",
    "    # all_jobs_to_wait.extend(strong_scaling())\n",
    "    # all_jobs_to_wait.extend(weak_scaling())\n",
    "\n",
    "    print(\"Waiting for jobs to finish...\")\n",
    "    print(all_jobs_to_wait)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for job_name in tqdm(all_jobs_to_wait):\n",
    "    while not os.path.exists(f\"{data_folder}/{job_name}/timings.txt\"):\n",
    "        time.sleep(10)  # Poll every 10 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Timing Analysis\n",
    "\n",
    "In this section, we analyze the execution times for the one million forecasters test. We read the timing data from the generated files, calculate the mean and standard deviation of the execution times, and create a dataframe to summarize the results.\n",
    "\n",
    "The dataframe includes the following columns:\n",
    "- **Run**: The run identifier.\n",
    "- **Timing**: The total execution time for each run.\n",
    "- **Aggregate sum CPU time**: The sum of CPU times across all ranks for each run.\n",
    "- **Aggregate mean CPU time**: The mean CPU time across all ranks for each run.\n",
    "\n",
    "We then print the dataframe and the calculated mean and standard deviation of the execution times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "timings = []\n",
    "cpu_times = []\n",
    "\n",
    "for i in range(n_runs):\n",
    "    timing_file = f\"{data_folder}/ten_nodes_test/run_{i}/timings.txt\"\n",
    "    cpu_times_ranks = []\n",
    "    with open(timing_file, \"r\") as f:\n",
    "        line = f.readline().strip()\n",
    "        timing = float(line.replace(\"Total execution time: \", \"\"))\n",
    "        timings.append(timing)\n",
    "        for line in f:\n",
    "            cpu_times_ranks.append(float(line.strip().split(\":\")[1]))\n",
    "    cpu_times.append(cpu_times_ranks)\n",
    "\n",
    "mean_timing = np.mean(timings)\n",
    "std_timing = np.std(timings)\n",
    "\n",
    "# Create a dataframe\n",
    "df_timings = pd.DataFrame({\n",
    "    'Run': [f'run_{i}' for i in range(n_runs)],\n",
    "    'Timing': timings,\n",
    "    'Aggregate sum CPU time': [np.sum(cpu_times[i]) for i in range(n_runs)],\n",
    "    'Aggregate mean CPU time': [np.mean(cpu_times[i]) for i in range(n_runs)]\n",
    "})\n",
    "\n",
    "print(df_timings)\n",
    "\n",
    "# calculate the mean and std of the timings\n",
    "mean_timing = np.mean(df_timings['Timing'])\n",
    "std_timing = np.std(df_timings['Timing'])\n",
    "\n",
    "\n",
    "print(f\"Mean timing: {mean_timing}\")\n",
    "print(f\"Std timing: {std_timing}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strong Scalability Test\n",
    "\n",
    "In this section, we analyze the execution times for the strong scalability test. We have already submitted jobs for different numbers of nodes and collected the execution times. The results are plotted on a logarithmic scale to better visualize the differences in execution times as the number of nodes increases.\n",
    "\n",
    "The strong scalability test helps us understand how the execution time decreases as we increase the number of nodes while keeping the problem size constant. Ideally, the execution time should decrease proportionally with the increase in the number of nodes, indicating efficient parallelization and resource utilization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution_times_strong_scaling = []\n",
    "\n",
    "# Submit jobs for each test configuration\n",
    "for num_nodes in strong_scaling_nodes:\n",
    "    execution_time_file = f\"{data_folder}/strong_scaling/run_0/nodes_{num_nodes}/timings.txt\"\n",
    "\n",
    "    with open(execution_time_file, \"r\") as f:\n",
    "        line = f.readline().strip()\n",
    "        execution_time = float(line.replace(\"Total execution time: \", \"\"))\n",
    "    execution_times_strong_scaling.append(execution_time)\n",
    "    print(f\"Execution time for {num_nodes} nodes: {execution_time} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.yscale('log')\n",
    "plt.plot(strong_scaling_nodes, execution_times_strong_scaling, label='Strong Scaling', marker='o')\n",
    "plt.xlabel('Number of Nodes')\n",
    "plt.ylabel('Execution Time (seconds)')\n",
    "plt.title('Strong Scalability Test')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.savefig(f\"{charts_folder}/scalability_plot.png\") \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weak Scalability Test\n",
    "\n",
    "In this section, we analyze the execution times for the weak scalability test. \n",
    "\n",
    "The weak scalability test helps us understand how the execution time changes as we increase the number of nodes while keeping the workload per node constant. Ideally, the execution time should remain constant with the increase in the number of nodes, indicating efficient parallelization and resource utilization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# execution_times_weak_scaling = []\n",
    "\n",
    "# # Submit jobs for each test configuration\n",
    "# for num_nodes in weak_scaling_nodes:\n",
    "#     execution_time_file = f\"{data_folder}/weak_scaling/run_0/nodes_{num_nodes}_forecasters_{weak_scaling_forecasters*num_nodes}/timings.txt\"\n",
    "\n",
    "#     with open(execution_time_file, \"r\") as f:\n",
    "#         line = f.readline().strip()\n",
    "#         execution_time = float(line.replace(\"Total execution time: \", \"\"))\n",
    "#     execution_times_weak_scaling.append(execution_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Plot the weak scalability results\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.plot(weak_scaling_nodes, execution_times_weak_scaling, label='Weak Scaling', marker='o')\n",
    "# plt.xlabel(\"Number of Nodes\")\n",
    "# plt.ylabel(\"Execution Time (seconds)\")\n",
    "# plt.title(\"Weak Scalability Test\")\n",
    "# plt.grid(True)\n",
    "# plt.savefig(f\"{charts_folder}/weak_scalability.png\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "In this notebook, we have successfully set up and executed a series of scalability tests for an ensemble of forecasters in a high-performance computing environment. We started by importing the necessary libraries and setting up the directory structure. We then defined functions to submit jobs for one million forecasters, strong scaling, and weak scaling tests.\n",
    "\n",
    "We visualized the data generated from the one million forecasters test, analyzing the distribution of forecast, weights, and biases. The histograms confirmed that these variables are normally distributed, as expected.\n",
    "\n",
    "The strong scalability test demonstrated how the execution time decreases with an increasing number of nodes, indicating efficient parallelization. The weak scalability test showed that the execution time remains relatively constant as the number of nodes increases, suggesting good resource utilization.\n",
    "\n",
    "Overall, these tests provide valuable insights into the performance and scalability of our forecasting ensemble, helping us optimize and improve our high-performance computing workflows."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
